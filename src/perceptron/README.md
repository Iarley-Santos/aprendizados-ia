## ‚û°Ô∏è Perceptron em C++ ‚Äì Portas L√≥gicas OR e AND

Este reposit√≥rio cont√©m implementa√ß√µes em C++ de um perceptron de camada √∫nica, treinado para simular as portas l√≥gicas OR e AND. O objetivo √© entender, de forma pr√°tica e did√°tica, como funciona o algoritmo de aprendizado do perceptron.

## üîç O que √© um Perceptron?

O perceptron √© um modelo matem√°tico inspirado no funcionamento dos neur√¥nios biol√≥gicos, proposto por Frank Rosenblatt em 1958. Em um neur√¥nio biol√≥gico, os dendritos recebem sinais el√©tricos de outros neur√¥nios, processam esses sinais e, se a soma ultrapassar um determinado limiar, o neur√¥nio "dispara" um impulso el√©trico. Analogamente, o perceptron recebe m√∫ltiplas entradas, cada uma associada a um peso, calcula uma soma ponderada dessas entradas e aplica uma fun√ß√£o de ativa√ß√£o para determinar a sa√≠da.
Matematicamente, o funcionamento de um perceptron pode ser descrito da seguinte forma:

![Texto alternativo](caminho/para/imagem.png)

1. **Entradas**: Um vetor de valores de entrada ($$x = [x_1, x_2, ..., x_n]$$).
2. **Pesos**: Cada entrada possui um peso associado ($$w = [w_1, w_2, ..., w_n]$$).
3. **Soma ponderada**: Calcula-se a soma ponderada das entradas e adiciona-se um vi√©s ($b$ = bias):

$$
z = \sum_{i=1}^{n} w_i \cdot x_i + b
$$


4. **Fun√ß√£o de ativa√ß√£o**: Aplica-se uma fun√ß√£o de ativa√ß√£o √† soma ponderada para determinar a sa√≠da do perceptron. No caso mais simples, utiliza-se a fun√ß√£o degrau:

$$
f(z) = \begin{cases}
1, & \text{se } z \geq 0 \\
0, & \text{se } z < 0
\end{cases}
$$

üîÑDurante o treinamento, os pesos e o vi√©s s√£o ajustados iterativamente com base no erro entre a sa√≠da prevista e a sa√≠da desejada, utilizando a seguinte regra de atualiza√ß√£o:

$$
erro = d - y
$$

$$
w_i = w_i + \eta \cdot erro \cdot x_i
$$

$$
b = b + \eta \cdot erro
$$

Onde:
- $\eta$ : Taxa de aprendizado (learning rate).
- $d$ : Sa√≠da desejada.
- $y$: Sa√≠da prevista pelo perceptron.

Essa abordagem permite que o perceptron ajuste seus par√¢metros para minimizar o erro de classifica√ß√£o em problemas onde os dados s√£o **linearmente separ√°veis**.
